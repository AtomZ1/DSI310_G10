{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ede57ddb",
   "metadata": {},
   "source": [
    "02_entiry-extract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3582a79a",
   "metadata": {},
   "source": [
    "install extra library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f3c65a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\konto\\anaconda3\\lib\\site-packages (4.23.1)\n",
      "Requirement already satisfied: torch in c:\\users\\konto\\anaconda3\\lib\\site-packages (1.12.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\konto\\anaconda3\\lib\\site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\konto\\anaconda3\\lib\\site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\konto\\anaconda3\\lib\\site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\konto\\anaconda3\\lib\\site-packages (from transformers) (4.59.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\konto\\anaconda3\\lib\\site-packages (from transformers) (0.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in c:\\users\\konto\\anaconda3\\lib\\site-packages (from transformers) (0.10.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\konto\\anaconda3\\lib\\site-packages (from transformers) (1.20.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\konto\\anaconda3\\lib\\site-packages (from transformers) (2021.4.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\konto\\anaconda3\\lib\\site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: requests in c:\\users\\konto\\anaconda3\\lib\\site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\konto\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\konto\\anaconda3\\lib\\site-packages (from requests->transformers) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\konto\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\konto\\anaconda3\\lib\\site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\konto\\anaconda3\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8b6ff1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in c:\\users\\konto\\anaconda3\\lib\\site-packages (0.1.97)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b098299",
   "metadata": {},
   "source": [
    "read stored data from DataPlatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99c66cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsmlibrary.datanode import DataNode\n",
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce898d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_raw_id = <YOUR RAW DIR ID>\n",
    "dir_process_id = <YOUR PROCESS DIR ID>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c95f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "datanode = DataNode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581dbf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta, fp = datanode.get_file(datanode.get_file_id(directory_id=dir_raw_id, name='news.json'))\n",
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1711757d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.load(fp)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe896270",
   "metadata": {},
   "source": [
    "NER (NameEntitiesRegcognition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d57bd6d",
   "metadata": {},
   "source": [
    "extract entity from news description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23a5e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48033b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"Davlan/xlm-roberta-base-ner-hrl\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"Davlan/xlm-roberta-base-ner-hrl\")\n",
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7348daa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process(preds):\n",
    "    data = []\n",
    "    for i in range(len(preds)): \n",
    "        a = preds[i]\n",
    "        text = a.get('word')\n",
    "        for j in range(i, len(preds)):\n",
    "            b = preds[j]\n",
    "            if b.get('start') == a.get('end'):\n",
    "                text += b.get('word')\n",
    "                a = b\n",
    "        data.append({\n",
    "            'type': a.get('entity'),\n",
    "            'text': text\n",
    "        })\n",
    "    tmp = []\n",
    "    for elm in data:\n",
    "        text = elm.get('text')\n",
    "        if bool(re.match(\"[ก-๛]|▁\", text)):\n",
    "            elm.update({'text': text.replace('▁', ' ')})\n",
    "            tmp.append(elm)\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4e1851",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = data[0]['description']\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e0a155",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = nlp(text)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6458da",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_process(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fae29d",
   "metadata": {},
   "source": [
    "Process news to spo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a237f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "spo = []\n",
    "for news in tqdm(data):\n",
    "    description = news.get('description') \n",
    "    if description == None:\n",
    "        continue\n",
    "    ner = nlp(description)\n",
    "    processed = post_process(ner)\n",
    "    for kw in processed:\n",
    "        spo.append({\n",
    "            'subject': news.get('title', \"\"),\n",
    "            'predicate': kw.get('type', \"\"),\n",
    "            'object': kw.get('text', \"\")\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a654b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(spo)\n",
    "df['predicate'] = df['predicate'].apply(lambda x: x[2:])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d54bb6a",
   "metadata": {},
   "source": [
    "write DataNode to DataPlatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950b5a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "datanode.write(df=df, directory=dir_process_id, name=\"spo\", profiling=True, lineage=[datanode.get_file_id(directory_id=dir_raw_id, name='vogue.json')])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
